## åŸºäºansibleä½¿ç”¨äºŒè¿›åˆ¶å¿«é€Ÿéƒ¨ç½²k8s-v1.19

[è¯¦ç»†éƒ¨ç½²è¯´æ˜](./ansible-install-k8s-all.md)

### tls/sslè¯ä¹¦æ„å»º

```
# ä¸‹è½½è¯ä¹¦ç›¸å…³æ–‡ä»¶(å·¥å…·åŒ…,å¯ä»¥åœ¨ansibleä¸»æœºä¸Šç»Ÿä¸€ç”Ÿæˆ)
$ wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64
$ wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64
$ wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64
$ chmod a+x *amd64

$ mv cfssl_linux-amd64 /usr/sbin/cfssl
$ mv cfssljson_linux-amd64 /usr/sbin/cfssljson
$ mv cfssl-certinfo_linux-amd64 /usr/sbin/cfssl-certinfo

```

#### 0.åˆ›å»ºæ ¹è¯ä¹¦(CA)

æ³¨æ„:k8sé›†ç¾¤å’Œetcdé›†ç¾¤å…¬ç”¨ä¸€ä¸ªcaè¿›è¡Œè¯ä¹¦é¢å‘,åç»­åˆ›å»ºçš„æ‰€æœ‰è¯ä¹¦éƒ½ç”±æ ¹è¯ä¹¦ç­¾å

```
# åˆ›å»ºcaè¯ä¹¦é…ç½®æ–‡ä»¶
$ cat ca-ssl/ca-config.json
{
  "signing": {
    "default": {
      "expiry": "876000h"
    },
    "profiles": {
      "kubernetes": {
        "usages": [
            "signing",
            "key encipherment",
            "server auth",
            "client auth"
        ],
        "expiry": "876000h"
      }
    }
  }
}
## signing è¡¨ç¤ºè¯¥è¯ä¹¦å¯ç”¨äºç­¾åå…¶å®ƒè¯ä¹¦ï¼Œç”Ÿæˆçš„ca.pemè¯ä¹¦æ‰¾ä¸­CA=TRUE
## server auth è¡¨ç¤ºclientå¯ä»¥ç”¨è¯¥è¯ä¹¦å¯¹serveræä¾›çš„è¯ä¹¦è¿›è¡ŒéªŒè¯
## client auth è¡¨ç¤ºserverå¯ä»¥ç”¨è¯¥è¯ä¹¦å¯¹clientæä¾›çš„è¯ä¹¦è¿›è¡ŒéªŒè¯


# åˆ›å»ºè¯ä¹¦ç­¾åè¯·æ±‚æ–‡ä»¶
$ cat ca-ssl/ca-csr.json
{
  "CN": "kubernetes",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "ST": "BeiJing",
      "L": "BeiJing",
      "O": "k8s",
      "OU": "System"
    }
  ],
  "ca": {
    "expiry": "876000h"
 }
}

## CN CommonName,kube-apiserverä»è¯ä¹¦ä¸­æå–è¯¥å­—æ®µä½œä¸ºè¯·æ±‚çš„ç”¨æˆ·å(User Name)ï¼Œæµè§ˆå™¨ä½¿ç”¨è¯¥å­—æ®µéªŒè¯ç½‘ç«™æ˜¯å¦åˆæ³•
## O Organization,kube-apiserver ä»è¯ä¹¦ä¸­æå–è¯¥å­—æ®µä½œä¸ºè¯·æ±‚ç”¨æˆ·å’Œæ‰€å±ç»„(Group)
## kube-apiserverå°†æå–çš„Userã€Groupä½œä¸ºRBACæˆæƒçš„ç”¨æˆ·å’Œæ ‡è¯†


# ç”Ÿæˆkeyå’Œç­¾åè¯ä¹¦
# ä½¿ç”¨cfssl gencert å‘½ä»¤æ¥ç”Ÿæˆæ–°keyå’Œç­¾åè¯ä¹¦
## è¯¥æŒ‡ä»¤å¯ç”¨äºä»CSRé…ç½®(CSRJSON ä¸Šè¿°çš„ca-csr.json)ä¸­ç”Ÿæˆkeyå’Œè¯ä¹¦ï¼›ä½¿ç”¨CAçš„keyå’ŒCSRæ¥é‡ç­¾CAè¯ä¹¦ï¼›æˆ–è€…ä½¿ç”¨CAçš„keyå’Œè¯ä¹¦æ¥é‡ç­¾CAè¯ä¹¦
$ pushd 
$ cfssl gencert -initca ca-csr.json
......
......
2020/09/13 07:14:58 [INFO] signed certificate with serial number 8586413332462455829602406972761074712627171945
{"cert":"-----BEGIN CERTIFICATE-----\nMIIDwDCCAqigAwIBAgIUAYEHMOpThhfzOhAEcUk8BXkc0mkwDQYJKoZIhvcNAQEL\nBQAwZTELMAkGA1UEBhMCQ04xEDAOBgNVBAgTB0JlaUppbmcxEDAOBgNVBAcTB0Jl\naUppbmcxDDAKBgNVBAoTA2s4czEPMA0GA1UECxMGU3lzdGVtMRMwEQYDVQQDEwpr\ndWJlcm5ldGVzMCAXDTIwMDkxMzA3MTAwMFoYDzIxMjAwODIwMDcxMDAwWjBlMQsw\nCQYDVQQGEwJDTjEQMA4GA1UECBMHQmVpSmluZzEQMA4GA1UEBxMHQmVpSmluZzEM\nMAoGA1UEChMDazhzMQ8wDQYDVQQLEwZTeXN0ZW0xEzARBgNVBAMTCmt1YmVybmV0\nZXMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQChH10PemY3yg5XL1zg\nYMhtNHJ1Crz9iUcYpK7aK8609v6XyzvqzjMlIbL9Fz8yC8+n6Tul3BsgirScIoei\njxStV2c89CLVVDTf+9CxfyWVrogH1zoUJ15qyxUXb4vS95q2wRDcwkckW9T8UzLB\npoJnjEyf/FAR9u4UOxaNaZzpCkNdY6JSOOU5fMI/XBdUxHx9aaefHxvVEQpI7hAH\nZwXqEAQIvWLrZsq6kqFQyppja/pkn9Y9IDRD4fb/csdie7dpITkuxS78YvoF0UzA\nnzxVzGxb6s5D+LLQAiWfoKhztd+L4GwcwLzie0m6ddAz7sR321YCfWbcju/BRcYm\nta99AgMBAAGjZjBkMA4GA1UdDwEB/wQEAwIBBjASBgNVHRMBAf8ECDAGAQH/AgEC\nMB0GA1UdDgQWBBR11h6uvnICj2nE2GWHPnygS6d+mzAfBgNVHSMEGDAWgBR11h6u\nvnICj2nE2GWHPnygS6d+mzANBgkqhkiG9w0BAQsFAAOCAQEAe2FMMKtiYmTs3SGi\nKIPbGmo246gGGV9BGZ4pgkWtWYa0TeV2S4fINHZsunxhuUuXEzRXQe/M4KfOE3Fk\nAC3yrdO7mReaX8Jw97VLsU35IXNYvKruQb5NjDn71j08UEUMGRqr7mXsl1E3Z7uM\nt2CQXjHAG6qFK/i76nQOOAWmHPQAMzJtTVbXXCJGpeW9PBMVR7awA356gn7ciuN8\njgH/vQ5223zMcI3V5KTQ9ssqU0UIrQ65+p9a+KTkhtVxmOv2lYiuTBra9aP/S0Vf\nAHGC+e9RNPxq+fs6uPspk6yy/LNK5Eb1H9xibxZ3abD8X7Ujl6Duo3+goUFonv6E\nZ9u4Uw==\n-----END CERTIFICATE-----\n","csr":"-----BEGIN CERTIFICATE REQUEST-----\nMIICqjCCAZICAQAwZTELMAkGA1UEBhMCQ04xEDAOBgNVBAgTB0JlaUppbmcxEDAO\nBgNVBAcTB0JlaUppbmcxDDAKBgNVBAoTA2s4czEPMA0GA1UECxMGU3lzdGVtMRMw\nEQYDVQQDEwprdWJlcm5ldGVzMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKC\nAQEAoR9dD3pmN8oOVy9c4GDIbTRydQq8/YlHGKSu2ivOtPb+l8s76s4zJSGy/Rc/\nMgvPp+k7pdwbIIq0nCKHoo8UrVdnPPQi1VQ03/vQsX8lla6IB9c6FCdeassVF2+L\n0veatsEQ3MJHJFvU/FMywaaCZ4xMn/xQEfbuFDsWjWmc6QpDXWOiUjjlOXzCP1wX\nVMR8fWmnnx8b1REKSO4QB2cF6hAECL1i62bKupKhUMqaY2v6ZJ/WPSA0Q+H2/3LH\nYnu3aSE5LsUu/GL6BdFMwJ88VcxsW+rOQ/iy0AIln6Coc7Xfi+BsHMC84ntJunXQ\nM+7Ed9tWAn1m3I7vwUXGJrWvfQIDAQABoAAwDQYJKoZIhvcNAQELBQADggEBAAFV\ncqE7Er1A5gCTn6K6Ol/cbu02EiAjkmV1jXuNw/40S9tdUBkithwC27qmrYU+Za26\nxjHq6YUMDxP13OHUZPUBaT8U1dw+/u93Jx7ZitYfIhG6QyU+c5WpLvjmL1UT3v9G\nfXsAD9FFtSbaGgbUdCn8o+GJuQ+zNuoLetF2/YLqVI2RwbIY9+3VWFS6CvGethVo\nUFGbR3lF5Jktx1r+NrqZT1ERyIkr2IK8uVLDCMpGboqBX32FfeAFHABlZUpe4Hjz\nT0Te2sFAkA6wWjUhaZMW815yMygkTI4snwt1uxfBN4I1x8AgAndY8a2mRuEd83zy\nAfTv9ANX7msvihRZVQU=\n-----END CERTIFICATE REQUEST-----\n","key":"-----BEGIN RSA PRIVATE KEY-----\nMIIEpQIBAAKCAQEAoR9dD3pmN8oOVy9c4GDIbTRydQq8/YlHGKSu2ivOtPb+l8s7\n6s4zJSGy/Rc/MgvPp+k7pdwbIIq0nCKHoo8UrVdnPPQi1VQ03/vQsX8lla6IB9c6\nFCdeassVF2+L0veatsEQ3MJHJFvU/FMywaaCZ4xMn/xQEfbuFDsWjWmc6QpDXWOi\nUjjlOXzCP1wXVMR8fWmnnx8b1REKSO4QB2cF6hAECL1i62bKupKhUMqaY2v6ZJ/W\nPSA0Q+H2/3LHYnu3aSE5LsUu/GL6BdFMwJ88VcxsW+rOQ/iy0AIln6Coc7Xfi+Bs\nHMC84ntJunXQM+7Ed9tWAn1m3I7vwUXGJrWvfQIDAQABAoIBAB2J8Xa3+ut5eL2V\nKlLci4Ix3lYE3PciZs1my8OlymS076IGmXqHySqijf0GeQiEz9I52TykKLkDlO8X\nCYTM9H5/CqdLHuO7Z2I0+WLBK7PQZpIBbF1rhkzP5JMCWUEZMd0VcjD20TIiP97u\npdyI2VmAiD/AczGH8sf0uUK9vQ2gEIw/265i7js04f/r9Dy3sp1vHMzNUcDaYVdt\n+qEhoF8xOZM07YJQjcQsDbRDVjU+Sppf//hwPiiApR6pENSFqCDk2k5WKGoTDoem\nnjP3kFfz48miN35N6Yh5DFrfSkIa+V/cPileTMV1cuSob48AtLcImZ69CjncSO2C\nK/WJBmECgYEA0kHIk79WIyb1r2DovvpNIT4Uf2HgxrbvWS33fvKyjFH7s4ZAa+ff\nG5YoVpF9mnUNA1G0nSxIilLwhZN/F8m/87Ya7fz2ik1GaT+aDApqNKxoF+k7gPQP\nuuVRck0K5hXsGXB1mEs7uFwqflHFc1/6w9KuA6yZ/7EfFH1Pf8aUAskCgYEAxC0M\nFye4qgkWGeeBxDGPCtq6bEX6CF4HDeZp+94iEOAgOtpYpJ2Y8Nuipp1xjU9ephgg\nSmD47qOwccGO6oS3UZyL4eoD2feWQasyHviEwMNnBSIfwYznCHFLKAraV708vA3K\nBnkF5iAJ68WD5BLS1YE0YatK9E6wSt/W9yRjTRUCgYEAzd/h8WGZi0P7r2UZoN5f\npZwu3+fL+2dmh5Dt1Vz5HVKtPcTH0aCyIkXua418SkAwpL5dNsUEpoS9xF1/RaCj\nlpQKXFukYBl4R1gik4WjJr5mEnuqawMPX/ZowJ3VfSOcEfC/BIcuC8AbT6LrzqP9\nW78v6qMYC3i4MQzeSgP8K5kCgYEAwujm7FKg3P/uH4qumZmLv4MWWeEkzQ9u/taB\nUqefPRkRrKeoDtYuUJBICDbBzV6gcXHjE0NJ0QB9nGhtcICwCrv5F1qEvRmLBm/r\nem38p/D8+FKxLoKqQO8fdwdhbG8uWsFwigHQZJZMhR5XLlGtfEfFHY0tCZLtAVdo\no2BZ8QkCgYEAqfZ0VEMJPS3riHSjahG/ZTqAjBkLVXosyKpkQaZ/zTVVOQYjmHOb\nC5aV4GvbeIEtjmPmZOc6KTiKatfN/IRJybzl1QAi97xUqiPZ5pJV5vhF1fjVk7e5\n2yVjZe9PSAIHQeipGXhv6MLuP+hgNQHUIT+PotuTpeZzC/R1tDzIHNo=\n-----END RSA PRIVATE KEY-----\n"}

# å¦‚ä¸ŠæŒ‡ä»¤ä¼šæ ¹æ®å½“å‰CA-CSRçš„é…ç½®æ¥ç”ŸæˆCSRè¯·æ±‚ï¼ŒCAçš„keyä»¥åŠCAçš„è¯ä¹¦ï¼Œä½†æ˜¯ä¼šæ”¾åœ¨ä¸€ä¸ªå¤§jsonä¸²ä¸­ï¼Œå› æ­¤é€šå¸¸æˆ‘ä»¬éœ€è¦ä½¿ç”¨cfssljsonå·¥å…·è¿›è¡Œè½¬å‚¨
# cfssljson æ˜¯ä¸€ä¸ªä¸“é—¨ä»CFSSLå“åº”ä½“ä¸­è§£æå¹¶ä¿å­˜åˆ°jsonæ–‡ä»¶çš„ä¸€ä¸ªå·¥å…·
$ cfssl gencert -initca ca-csr.json  | cfssljson -bare ca
2020/09/13 07:20:26 [INFO] generating a new CA key and certificate from CSR
2020/09/13 07:20:26 [INFO] generate received request
2020/09/13 07:20:26 [INFO] received CSR
2020/09/13 07:20:26 [INFO] generating key: rsa-2048
2020/09/13 07:20:27 [INFO] encoded CSR
2020/09/13 07:20:27 [INFO] signed certificate with serial number 306065836815286281292411979507270171176198785172


# æ­¤æ—¶ä¼šç”Ÿæˆä¸‰ä¸ªæ–‡ä»¶ca.csr,ca-key.pem,ca.pem å³æ‰€è°“çš„caè¯·æ±‚æ•°æ®ï¼Œcaçš„KEYï¼Œä»¥åŠcaè¯ä¹¦ã€‚
$ ll -t | head -4
total 20
-rw-r--r--  1 root root 1001 Sep 13 07:20 ca.csr
-rw-------  1 root root 1679 Sep 13 07:20 ca-key.pem
-rw-r--r--  1 root root 1363 Sep 13 07:20 ca.pem

# éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œé€šå¸¸æƒ…å†µä¸‹æˆ‘ä»¬çš„è¯ä¹¦å¯èƒ½ä¼šè¿‡æœŸï¼Œåœ¨è¿‡æœŸå‰ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ca-key.pem å’Œca.pemæˆ–CSRJSON(ca-csr.json) æ¥å¯¹caè¯ä¹¦è¿›è¡Œé‡ç­¾ï¼Œä»¥ä½¿ä¹‹ç»§ç»­å¯ç”¨ã€‚


```

#### 1.åˆ›å»ºetcdè¯ä¹¦

```
# åˆ›å»ºetcdè¯ä¹¦çš„è¯·æ±‚æ–‡ä»¶
$ cat etcd-ssl/etcd-csr.json
{
  "CN": "etcd",
  "hosts": [
    "127.0.0.1",
    "192.168.0.230",
    "192.168.0.145",
    "192.168.0.23"
  ],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "ST": "BeiJing",
      "L": "BeiJing",
      "O": "k8s",
      "OU": "System"
    }
  ]
}


# ç”±äºæˆ‘ä»¬å‰é¢å·²ç»åˆå§‹åŒ–å¥½äº†CAç›¸å…³çš„keyå’Œè¯ä¹¦ï¼Œè¿™é‡Œetcdé›†ç¾¤ç›´æ¥ä½¿ç”¨ä¹‹å‰çš„CAç›¸å…³è¯ä¹¦å’Œé…ç½®å³å¯
$ pushd etcd-ssl/

# è¿™é‡Œæˆ‘ä»¬åœ¨ç”Ÿæˆetcdçš„è¯ä¹¦æ—¶ä¼šæŒ‡å®šä¸€ä¸ªé…ç½®æ–‡ä»¶ï¼Œä¹Ÿå°±æ˜¯å‰é¢çš„ca-config.jsonï¼Œè¯¥æ–‡ä»¶ä¸­ç»Ÿä¸€å£°æ˜äº†è¯ä¹¦ä¸€äº›å…¬å…±é…ç½®ï¼Œæ¯”å¦‚æœ‰æ•ˆæœŸï¼Œprofilesç­‰åŸºæœ¬é…ç½®ï¼Œå› ä¸ºæˆ‘ä»¬çš„etcdè¯ä¹¦æ˜¯ä¸ºkuberneteså’Œetcdæ¥ä½¿ç”¨ï¼Œå› æ­¤ä¹Ÿéœ€è¦æŒ‡å®šprofile(åœ¨profileä¸­æˆ‘ä»¬å®šä¹‰äº†kubernetesè¿™ä¸ªé…ç½®ï¼Œå…¶ä¸­ä¹Ÿå£°æ˜äº†å®ƒçš„ç”¨é€”å’ŒæœŸé™)

$ cfssl gencert -ca="../ca-ssl/ca.pem" -ca-key="../ca-ssl/ca-key.pem"   -config="../ca-ssl/ca-config.json" -profile=kubernetes etcd-csr.json
.....
.....


# å¦‚ä¸Šä¾ç„¶ä¼šç”Ÿæˆè¯ä¹¦ç›¸å…³çš„ä¸‰ä¸ªæ–‡ä»¶ï¼Œå³key,cert,csr æ­¤æ—¶ï¼Œæˆ‘ä»¬ä¾ç„¶éœ€è¦ä½¿ç”¨cfssljosnå·¥å…·å°†å…¶ä¿å­˜æˆjsonæ–‡ä»¶

$ cfssl gencert -ca="../ca-ssl/ca.pem" -ca-key="../ca-ssl/ca-key.pem"   -config="../ca-ssl/ca-config.json" -profile=kubernetes etcd-csr.json  | cfssljson -bare etcd

$ ll -t * | head -4
-rw-r--r-- 1 root root 1062 Sep 13 07:44 etcd.csr
-rw------- 1 root root 1675 Sep 13 07:44 etcd-key.pem
-rw-r--r-- 1 root root 1436 Sep 13 07:44 etcd.pem
 
```


#### 2.åˆ›å»ºk8s-masterç›¸å…³è¯ä¹¦

`æ³¨æ„:` é€šå¸¸å¯¹å¤–æš´éœ²çš„master-apiæ˜¯ä¸€ä¸ªæ— çŠ¶æ€çš„æœåŠ¡ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨ä¸€äº›è´Ÿè½½å‡è¡¡æŠ€æœ¯æ¥å¯¹å¤–ç»Ÿä¸€æš´éœ²master-apiæ¥å£ï¼Œå› æ­¤å»ºè®®å°†master-apiä½¿ç”¨è´Ÿè½½å‡è¡¡æŠ€æœ¯ï¼Œå¹¶ä¸”è®©å®¢æˆ·ç«¯(äºŒæ¬¡å¼€å‘æˆ–è€…nodeèŠ‚ç‚¹)ä½¿ç”¨åŸŸåè¿›è¡Œæ¥å…¥ã€‚

```

# 192.168.0.110 ä¸ºæˆ‘ä»¬çš„master-apiçš„è´Ÿè½½å‡è¡¡åœ°å€(ä¹Ÿå¯æ˜¯keepalive+nginxçš„è™šæ‹Ÿåœ°å€ï¼Œä¿è¯é«˜å¯ç”¨å³å¯)
# 10.253.0.1 ä¸ºé›†ç¾¤ä¸­é»˜è®¤çš„kubernetesçš„svcåœ°å€ï¼Œä¸€èˆ¬CRDé€šå¸¸éƒ½ä¼šè°ƒç”¨å†…éƒ¨çš„kubernetesçš„é»˜è®¤svcåœ°å€ï¼Œæ¥å’Œé›†ç¾¤è¿›è¡Œé€šä¿¡
$ cat k8s-ssl/k8s-csr.json
{
    "CN": "kubernetes",
    "hosts": [
      "127.0.0.1",
      "192.168.0.230",
      "192.168.0.145",
      "192.168.0.145",
      "192.168.0.110",
      "k8s-master-api.goops.top",
      "10.253.0.1",
      "kubernetes",
      "kubernetes.default",
      "kubernetes.default.svc",
      "kubernetes.default.svc.cluster",
      "kubernetes.default.svc.cluster.local"
    ],
    "key": {
        "algo": "rsa",
        "size": 2048
    },
    "names": [
        {
            "C": "CN",
            "L": "Beijing",
            "ST": "Beijing",
            "O": "k8s",
            "OU": "System"
        }
    ]
}


# ç”ŸæˆmasterèŠ‚ç‚¹çš„è¯ä¹¦å’Œkey

$ pushd k8s-ssl
$ cfssl gencert -ca=../ca-ssl/ca.pem -ca-key=../ca-ssl/ca-key.pem -config=../ca-ssl/ca-config.json -profile=kubernetes k8s-csr.json | cfssljson -bare k8s
.....
.....

$ ll -t k8s* | head -4
-rw-r--r--. 1 root root 1301 Sep 13 08:02 k8s.csr
-rw-r--r--. 1 root root 1679 Sep 13 08:02 k8s-key.pem
-rw-r--r--. 1 root root 1675 Sep 13 08:02 k8s.pem
-rw-r--r--  1 root root  616 Sep 13 07:56 k8s-csr.json

```


#### 3.åˆ›å»ºkube-proxyè¯ä¹¦

`æ³¨æ„:` ç”±äºkube-proxyå…¶å®ä¹Ÿæ˜¯æ•´ä¸ªé›†ç¾¤çš„ä¸€ä¸ªè§’è‰²ï¼Œå› æ­¤ç›´æ¥ä½¿ç”¨k8s-masterçš„è¯ä¹¦ä¹Ÿæ˜¯æ²¡æœ‰é—®é¢˜çš„ï¼Œä½†ç”±äºkube-proxyçš„è§’è‰²ç›¸å¯¹æ¯”è¾ƒé‡è¦ï¼Œé€šå¸¸æˆ‘ä»¬ä¼šç»™æŒ‡å®šçš„User(`system:kube-proxy`)å•ç‹¬åˆ›å»ºä¸€ä¸ªè¯ä¹¦ã€‚


```
$ cat kube-proxy-csr.json
{
  "CN": "system:kube-proxy",
  "hosts": [],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "L": "Beijing",
      "ST": "Beijing",
      "O": "k8s",
      "OU": "System"
    }
  ]
}

$ ll -t kube-proxy* | head -4
-rw-r--r--. 1 root root 1009 Sep 13 08:08 kube-proxy.csr
-rw-r--r--. 1 root root 1675 Sep 13 08:08 kube-proxy-key.pem
-rw-r--r--. 1 root root 1403 Sep 13 08:08 kube-proxy.pem
-rw-r--r--  1 root root  230 Sep 13 08:08 kube-proxy-csr.json


```

è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»æŒ‰ç…§æˆ‘ä»¬çš„è§„åˆ’ï¼Œå°†CAè¯ä¹¦å’Œkeyï¼Œetcdçš„è¯ä¹¦å’Œkeyï¼Œk8sçš„è¯ä¹¦å’Œkeyä»¥åŠkube-proxyçš„è¯ä¹¦å’ŒkeyåŸºæœ¬å‡†å¤‡å®Œæ¯•ï¼Œæ¥ä¸‹æ¥å°±æ˜¯æ¥åˆå§‹åŒ–å„ä¸ªé›†ç¾¤è§’è‰²äº†ã€‚

### å®‰è£…Etcdé›†ç¾¤

`æ³¨æ„:` æˆ‘ä»¬ä½¿ç”¨etcd-v3.4.13ç‰ˆæœ¬æ¥æ­å»ºé›†ç¾¤ï¼Œå€¼å¾—å…³æ³¨çš„æ˜¯ï¼Œåœ¨etcdv3.4ç‰ˆæœ¬ä¹‹åé»˜è®¤ä½¿ç”¨äº†V3çš„APIæ¥å£ï¼Œåé¢çš„æ•´ä¸ªé›†ç¾¤éƒ¨ç½²éœ€è¦æ³¨æ„è¿™é‡Œ(flannelæš‚ä¸æ”¯æŒV3æ¥å£)


```
# æ³¨æ„: è¯¥hostsæ–‡ä»¶åœ¨ansible-playbooks é¡¹ç›®ä¸‹

$ cat hosts
[master]
192.168.0.230 nodename=etcd01
192.168.0.145 nodename=etcd02
192.168.0.23 nodename=etcd03

# æ‰§è¡Œansible-playbook çš„etcd-install å‰§æœ¬

$ ansible-playbook  -i hosts -e host=all etcd-install.yml

PLAY [all] ************************************************************************************************************************************

TASK [Gathering Facts] ************************************************************************************************************************
ok: [192.168.0.23]
ok: [192.168.0.145]
ok: [192.168.0.230]

.....
.....
.....


# æ›´æ–°å®Œæˆåç¡®è®¤ä¸‹é…ç½®

$ ansible -i hosts all -m shell -a "cat /data/etcd/cfg/etcd.conf | egrep 'ETCD_NAME|PEER_URLS'"
192.168.0.230 | CHANGED | rc=0 >>
ETCD_NAME="etcd01"
ETCD_LISTEN_PEER_URLS="https://192.168.0.230:2380"
ETCD_INITIAL_ADVERTISE_PEER_URLS="https://192.168.0.230:2380"
192.168.0.23 | CHANGED | rc=0 >>
ETCD_NAME="etcd03"
ETCD_LISTEN_PEER_URLS="https://192.168.0.23:2380"
ETCD_INITIAL_ADVERTISE_PEER_URLS="https://192.168.0.23:2380"
192.168.0.145 | CHANGED | rc=0 >>
ETCD_NAME="etcd02"
ETCD_LISTEN_PEER_URLS="https://192.168.0.145:2380"
ETCD_INITIAL_ADVERTISE_PEER_URLS="https://192.168.0.145:2380"

# æ‰¹é‡å¯åŠ¨é›†ç¾¤(è¿™é‡Œåªæ˜¯ä¸ºäº†æ¼”ç¤ºæ•´ä¸ªansibleå‰§æœ¬çš„æ ‡å‡†åŒ–å’Œå‡†ç¡®æ€§ï¼Œå…¶å®å¯åŠ¨ä¹Ÿå¯ä»¥ç›´æ¥æ·»åŠ è‡³etcd-installå‰§æœ¬ä¸­)

$ ansible -i hosts all -m shell -a 'systemctl daemon-reload && systemctl restart etcd && systemctl enable etcd'
....
....




# æµ‹è¯•etcdé›†ç¾¤æ˜¯å¦æ­£å¸¸

$ ansible -i hosts all -m shell -a 'etcdctl --cacert="/data/etcd/ssl/ca.pem" --key="/data/etcd/ssl/etcd-key.pem" --cert="/data/etcd/ssl/etcd.pem" --endpoints=192.168.0.230:2379,192.168.0.145:2379,192.168.0.23:2379 endpoint status'
192.168.0.145 | CHANGED | rc=0 >>
192.168.0.230:2379, c2932a8aaaebe259, 3.4.13, 20 kB, false, false, 40, 9, 9,
192.168.0.145:2379, 4b1c1019f5515c8c, 3.4.13, 20 kB, true, false, 40, 9, 9,
192.168.0.23:2379, a2721e6aeb23ec8e, 3.4.13, 20 kB, false, false, 40, 9, 9,
192.168.0.23 | CHANGED | rc=0 >>
192.168.0.230:2379, c2932a8aaaebe259, 3.4.13, 20 kB, false, false, 40, 9, 9,
192.168.0.145:2379, 4b1c1019f5515c8c, 3.4.13, 20 kB, true, false, 40, 9, 9,
192.168.0.23:2379, a2721e6aeb23ec8e, 3.4.13, 20 kB, false, false, 40, 9, 9,
192.168.0.230 | CHANGED | rc=0 >>
192.168.0.230:2379, c2932a8aaaebe259, 3.4.13, 20 kB, false, false, 40, 9, 9,
192.168.0.145:2379, 4b1c1019f5515c8c, 3.4.13, 20 kB, true, false, 40, 9, 9,
192.168.0.23:2379, a2721e6aeb23ec8e, 3.4.13, 20 kB, false, false, 40, 9, 9,


```


### Kube-Masteréƒ¨ç½²

- kube-apiserver
- kube-scheduler
- kube-controller-manager

`æ³¨æ„:` k8s-masterçš„è¯ä¹¦æˆ‘ä»¬å‰é¢å·²ç»ç”Ÿæˆäº†,åœ¨k8s-sslç›®å½•(masterèŠ‚ç‚¹ç»Ÿä¸€ä½¿ç”¨ä¸€å¥—è¯ä¹¦)

`æ³¨æ„:` åœ¨`k8s-master-install.yml`ä¸­çš„`app_version`éœ€è¦æ”¹æˆå®˜æ–¹é»˜è®¤ä¸‹è½½çš„äºŒè¿›åˆ¶åŒ…çš„ç›®å½•ï¼›`etcd_endpoints`éœ€è¦æ”¹æˆä¸Šé¢çš„etcdçš„åœ°å€ã€‚

```
# ç”ŸæˆBootstrappingé…ç½®æ–‡ä»¶(ç”¨æ¥å¯¹kubeletç¬¬ä¸€æ¬¡æˆæƒ)
$ echo `head -c 16 /dev/urandom | od -An -t x | tr -d ' '`,kubelet-bootstrap,10001,\"system:kubelet-bootstrap\"  > templates/token.csv
$ cat templates/token.csv

# ä½¿ç”¨ansible-playbooksç»Ÿä¸€éƒ¨ç½²k8s-masteråŸºç¡€ç¯å¢ƒ
$ ansible-playbook -i hosts -e host=master k8s-master-install.yml
.....
.....

# æ‰¹é‡å¯åŠ¨k8s-masterèŠ‚ç‚¹å…¨éƒ¨ç»„ä»¶
$ ansible -i hosts master -m shell -a "systemctl daemon-reload && systemctl restart kube-apiserver kube-controller-manager kube-scheduler && systemctl enable kube-apiserver kube-controller-manager kube-scheduler"


# æ£€æŸ¥masterèŠ‚ç‚¹è§’è‰²æ˜¯å¦æ­£å¸¸
# è¿™é‡Œå¯ä»¥çœ‹åˆ°åœ¨v1.19ç‰ˆæœ¬ä¸­ï¼Œv1ç‰ˆæœ¬çš„ComponentStatus å·²ç»è¢«å¼ƒç”¨
$ ansible -i hosts all -m shell -a "kubectl get cs,nodes"
192.168.0.230 | CHANGED | rc=0 >>
NAME                                 STATUS    MESSAGE             ERROR
componentstatus/controller-manager   Healthy   ok
componentstatus/scheduler            Healthy   ok
componentstatus/etcd-0               Healthy   {"health":"true"}
componentstatus/etcd-2               Healthy   {"health":"true"}
componentstatus/etcd-1               Healthy   {"health":"true"}   Warning: v1 ComponentStatus is deprecated in v1.19+
192.168.0.145 | CHANGED | rc=0 >>
NAME                                 STATUS    MESSAGE             ERROR
componentstatus/controller-manager   Healthy   ok
componentstatus/scheduler            Healthy   ok
componentstatus/etcd-1               Healthy   {"health":"true"}
componentstatus/etcd-0               Healthy   {"health":"true"}
componentstatus/etcd-2               Healthy   {"health":"true"}   Warning: v1 ComponentStatus is deprecated in v1.19+
192.168.0.23 | CHANGED | rc=0 >>
NAME                                 STATUS    MESSAGE             ERROR
componentstatus/scheduler            Healthy   ok
componentstatus/controller-manager   Healthy   ok
componentstatus/etcd-0               Healthy   {"health":"true"}
componentstatus/etcd-2               Healthy   {"health":"true"}
componentstatus/etcd-1               Healthy   {"health":"true"}   Warning: v1 ComponentStatus is deprecated in v1.19+


```

åœ¨`kube-master`èŠ‚ç‚¹çš„æ‰€æœ‰ç»„ä»¶(kube-apiserver,kube-controller-manager,kube-scheduler)éƒ¨ç½²æˆåŠŸåï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`kubectl get cs,nodes`æ¥æŸ¥çœ‹ç»„ä»¶çš„çŠ¶æ€æ˜¯å¦å¥åº·ï¼Œä½†æ˜¯æˆ‘ä»¬ä¹Ÿå…³æ³¨åˆ°äº†ä¸€ä¸ªç»†èŠ‚ï¼Œå°±æ˜¯æœ‰ä¸€æ¡`Warning`çš„æ—¥å¿—æç¤º`v1ç‰ˆæœ¬çš„ ComponentStatus`æ¥å£å°†åœ¨ä»¥åçš„ç‰ˆæœ¬è¢«åºŸå¼ƒæ‰ã€‚

é€šè¿‡æŸ¥é˜…å®˜æ–¹[v1.19-Release-Notes-changes-by-kind](https://kubernetes.io/docs/setup/release/notes/#changes-by-kind)ä¸­æåˆ°ä¸‹é¢ä¸€å¥è¯: 

> Kube-apiserver: the componentstatus API is deprecated. This API provided status of etcd, kube-scheduler, and kube-controller-manager components, but only worked when those components were local to the API server, and when kube-scheduler and kube-controller-manager exposed unsecured health endpoints. Instead of this API, etcd health is included in the kube-apiserver health check and kube-scheduler/kube-controller-manager health checks can be made directly against those components' health endpoints. (#93570, @liggitt) [SIG API Machinery, Apps and Cluster Lifecycle]

å¤§æ¦‚æ„æ€å°±æ˜¯è¯´: `kube-apiserver` åœ¨æœªæ¥åºŸå¼ƒäº†`componentstatus`è¿™ä¸ªAPIã€‚è¯¥APIæä¾›äº†etcd,kube-shceduler,kube-controller-manager ç»„ä»¶çš„çŠ¶æ€ï¼Œä½†æ˜¯å®ƒä»…å½“è¿™äº›ç»„ä»¶å’ŒAPI Serveråœ¨ä¸€èµ·éƒ¨ç½²æ—¶ï¼Œå¹¶ä¸”å½“kube-schedulerå’Œkube-controller-manager æš´éœ²äº†éå®‰å…¨çš„å¥åº·ç«¯ç‚¹æ—¶ï¼Œæ‰æ­£å¸¸å·¥ä½œã€‚ä¸ºäº†ä»£æ›¿è¯¥APIï¼Œetcdçš„å¥åº·æ£€æŸ¥å‘—åŒ…å«è¿›äº†kube-apiserver çš„å¥åº·æ£€æŸ¥é€»è¾‘ä¸­ï¼Œå¹¶ä¸”kube-sheduler/kube-controller-manager å¯ä»¥ç›´æ¥é’ˆå¯¹è‡ªå·±çš„å¥åº·æ£€æŸ¥ç«¯ç‚¹è¿›è¡Œæ£€æŸ¥ã€‚å› æ­¤ï¼Œcomponentstatus è¿™ä¸ªæ¥å£å°±æ²¡æœ‰å¿…è¦äº†ã€‚

çœ‹åˆ°è¿™é‡Œï¼Œä¼šä¸ä¼šè§‰å¾—ï¼Œé¡¶çº§é¡¹ç›®çš„è®¾è®¡å’Œæ¼”è¿›å°±æ˜¯è¿™ä¹ˆå¹²å‡€å’Œåˆ©è½ï¼Œå›å¤´åœ¨æƒ³æƒ³è‡ªå·±å…¬å¸å…·ä½“çš„ä»£ç å§ğŸ˜­


### Kube-nodeéƒ¨ç½²

æ³¨æ„: åœ¨K8Sçš„æ•´ä¸ªç»„ä»¶å’Œæ¦‚å¿µä¸­ï¼Œå…¶å®nodeèŠ‚ç‚¹ä»…æœ‰ä¸¤ä¸ªè§’è‰²ï¼Œå³`kube-proxy`å’Œ`kubelet`ï¼Œå‰è€…ä¸»è¦è´Ÿè´£å°†æ‰€æœ‰çš„podçš„ç½‘ç»œé€šè¿‡ä¸€äº›åˆ—çš„è§„åˆ™åœ¨æ•´ä¸ªé›†ç¾¤æ‰“é€šï¼Œè€Œåè€…ä¸»è¦è´Ÿè´£æ•´ä¸ªpodçš„ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚ è€Œè‡³äºçœŸæ­£Podä¸­çš„å®¹å™¨ç”Ÿå‘½å‘¨å›´ç®¡ç†åˆ™é€šè¿‡Pluginçš„æ–¹å¼ç”±ä¸€äº›Runtimeè¿›è¡Œæ¥å…¥ï¼Œé€šå¸¸æˆ‘ä»¬å¸¸ç”¨ä¸”ç”Ÿäº§æˆç†Ÿçš„å°±æ˜¯å¤§åé¼é¼çš„Dockeräº†ï¼›ä½†åƒDockerè¿™ç§Runtime å…¶æœ¬èº«çš„ç½‘ç»œåˆæ— æ³•æ”¯æ’‘æ•´ä¸ªé›†ç¾¤ä»¥åŠä¸šåŠ¡çš„éœ€æ±‚ï¼Œå› æ­¤ç½‘ç»œä¸Šçš„æ”¯æ’‘ï¼Œä¹Ÿç”±kubeletæ¥é€šè¿‡Pluginçš„æ–¹å¼æ¥è¿›è¡ŒCNIæ¥å…¥ï¼Œåœ¨é€šç”¨å¼€æºçš„è§£å†³æ–¹æ¡ˆé‡Œï¼Œæ¯”è¾ƒå‡ºåçš„å°±æ˜¯ Flannel å’Œ Calico ä¸¤ä¸ªç»„ä»¶äº†ã€‚

å› æ­¤ï¼Œä¸€ä¸ªå¯çœŸæ­£è¿è¡Œçš„nodeèŠ‚ç‚¹åŒ…å«ä»¥ä¸‹ç»„ä»¶å’Œæ’ä»¶: 

- kubelet: Podçš„ç”Ÿå‘½å‘¨æœŸç®¡ç†
- kube-proxy: é›†ç¾¤ç½‘ç»œä»£ç†
- Runtime: å®¹å™¨è¿è¡Œæ—¶(Docker)
- CNI: å®¹å™¨ç½‘ç»œæ¥å£(Flannel/Calico) ã€ç”±äºflannelè¾ƒä¸ºç®€å•ï¼Œä¹‹å‰ä¸€ç›´ä½¿ç”¨flannelï¼Œä½†æ˜¯flannelé»˜è®¤ä¸æ”¯æŒETCD V3æ¥å£ï¼Œè¿™æ¬¡å°†ä½¿ç”¨Calicoæ¥æ„å»ºå®¹å™¨ç½‘ç»œã€‘


#### 0.ç”Ÿæˆbootstrapé…ç½®æ–‡ä»¶å’Œkube-proxyé…ç½®æ–‡ä»¶

````
$ export BOOTSTRAP_TOKEN=`cat /data/kubernetes/cfg/token.csv  | awk -F ',' '{print $1}'`
$ echo ${BOOTSTRAP_TOKEN}

# ä¸ºäº†éªŒè¯é›†ç¾¤ï¼Œæˆ‘ä»¬å¯ä»¥å…ˆä½¿ç”¨masterçš„ä»»æ„èŠ‚ç‚¹æ¥éƒ¨ç½²nodeèŠ‚ç‚¹(åæœŸå¯æ›¿æ¢æˆk8sè¯ä¹¦ä¸­hostséƒ¨åˆ†çš„åœ°å€)
# å½“ç„¶å¦‚æœæœ‰å®Œå¤‡çš„é«˜å¯ç”¨APIç½‘å…³æˆ–è€…SLBä¹‹ç±»çš„ï¼Œå¯ä»¥ç›´æ¥å°†kube apiserverçš„æ¥å£å¯¹å¤–åœ°å€é…ç½®
$ export KUBE_APISERVER="https://192.168.0.230:6443"

$ ls /data/kubernetes/ssl/ca.pem
# é…ç½®bootstrapé…ç½®æ–‡ä»¶
$ kubectl config set-cluster kubernetes --certificate-authority=/data/kubernetes/ssl/ca.pem --embed-certs=true --server=${KUBE_APISERVER} --kubeconfig=bootstrap.kubeconfig
$ kubectl config set-credentials kubelet-bootstrap --token=${BOOTSTRAP_TOKEN} --kubeconfig=bootstrap.kubeconfig
$ kubectl config set-context default --cluster=kubernetes  --user=kubelet-bootstrap --kubeconfig=bootstrap.kubeconfig

# åœ¨å½“å‰ç¯å¢ƒä¸­ä½¿ç”¨è¯¥ä¸Šä¸‹æ–‡
$ kubectl config use-context default --kubeconfig=bootstrap.kubeconfig

# é…ç½®kube-proxyçš„é…ç½®æ–‡ä»¶
$ kubectl config set-cluster kubernetes --certificate-authority=/data/kubernetes/ssl/ca.pem --embed-certs=true --server=${KUBE_APISERVER} --kubeconfig=kube-proxy.kubeconfig
$ kubectl config set-credentials kube-proxy --client-certificate=/data/kubernetes/ssl/kube-proxy.pem --client-key=/data/kubernetes/ssl/kube-proxy-key.pem --embed-certs=true --kubeconfig=kube-proxy.kubeconfig
$ kubectl config set-context default --cluster=kubernetes --cluster=kubernetes --user=kube-proxy --kubeconfig=kube-proxy.kubeconfig

# åœ¨å½“å‰ç¯å¢ƒä¸­ä½¿ç”¨è¯¥ä¸Šä¸‹æ–‡
$ kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig

# åœ¨é›†ç¾¤ä¸­åˆ›å»ºä¸€ä¸ªç”¨äºbootstrap çš„clusterrolebinding å°†system:node-bootstrapper è§’è‰²ç»‘å®šè‡³ç”¨æˆ·kubelet-bootstrap 
$ kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --user=kubelet-bootstrap
```

ç„¶åå°†ç”Ÿæˆçš„`bootstrap.kubeconfig` å’Œ `kube-proxy.kubeconfig` æ‹·è´åˆ°é¡¹ç›®çš„ `templates/` ä¸‹ã€‚


#### 1.æ‰¹é‡éƒ¨ç½²NodeèŠ‚ç‚¹è§’è‰²

`æ³¨æ„:` ç”±äºæˆ‘ä»¬å½“å‰å°†masterèŠ‚ç‚¹ä¹Ÿå……å½“nodeèŠ‚ç‚¹çš„è§’è‰²ï¼Œå› æ­¤ä¸‹è½½å’Œéƒ¨ç½²kubernetesæºç åŒ…çš„éƒ¨åˆ†å°±å¯ä»¥ç•¥è¿‡äº†ï¼Œå”¯ä¸€éœ€è¦å…³å¿ƒçš„å°±æ˜¯`kubelet`å’Œ`kube-proxy`çš„é…ç½®é—®é¢˜äº†ã€‚

```
$ ansible-playbook -i hosts -e host=master k8s-slave-install.yml --tags=config
....
....

PLAY RECAP ************************************************************************************************************************************
192.168.0.145              : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
192.168.0.23               : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
192.168.0.230              : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0

```


éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨kubelet çš„å¯åŠ¨é€»è¾‘é‡Œè®¾ç½®äº†kubelet å¿…é¡»åœ¨docker.service å¯åŠ¨ä¹‹åè¿›è¡Œå¯åŠ¨ï¼Œä¸ºäº†ä¿è¯æœåŠ¡çš„å°½å¯èƒ½çŸ­çš„å½±å“å‘¨æœŸã€‚

æ­¤æ—¶ï¼Œå¦‚æœèŠ‚ç‚¹ä¸Šçš„`docker`æœåŠ¡æ²¡æœ‰å¯åŠ¨ï¼Œç›´æ¥å¯åŠ¨`kubelet`ä¼šæç¤º`kubelet.service`ä¸å­˜åœ¨ã€‚


#### 3.éƒ¨ç½²Runtime è¿è¡Œæ—¶Dockerç»„ä»¶

```
# è¿™é‡Œéœ€è¦å…ˆéƒ¨ç½²dockerçš„è¿è¡Œæ—¶
$ ansible-playbook -i hosts -e host=all docker-install.yml
....
....
PLAY RECAP ************************************************************************************************************************************
192.168.0.145              : ok=7    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
192.168.0.23               : ok=7    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
192.168.0.230              : ok=7    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0


# å¯åŠ¨dockerï¼Œkubeletï¼Œkube-proxy æœåŠ¡
$ ansible -i hosts all -m shell -a "systemctl daemon-reload && systemctl restart docker"
.....
.....


```


#### 4.é…ç½®NodeèŠ‚ç‚¹ï¼Œå¹¶ç”Ÿæˆkubeletè¯ä¹¦

```
$ ansible -i hosts all -m shell -a "systemctl daemon-reload && systemctl restart kubelet kube-proxy"
....
....


# kubeletå¯åŠ¨åï¼Œä¼šè‡ªåŠ¨å‘kube apiserver å‘èµ·è®¤è¯è¯·æ±‚ã€‚
$ kubectl get csr
NAME                                                   AGE    SIGNERNAME                                    REQUESTOR           CONDITION
node-csr-01keemXrwk85QRvmxmKD7BL8Pe8-UpCYmEOdHovJMTE   40s    kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending
node-csr-mhdJODMPp8mQwJrnW-Gl2baQlWWgcrOvrYt3jmbw-dM   40s    kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending
node-csr-rgY6WzL2gwGFa5XyWLgJ4_ypJUPtbruuLloygUQ80P8   2m3s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Pending

# æ‰‹åŠ¨æ¥å—nodeçš„è¯·æ±‚
$ kubectl certificate approve node-csr-rgY6WzL2gwGFa5XyWLgJ4_ypJUPtbruuLloygUQ80P8
.....
.....

# æŸ¥çœ‹csrè¯·æ±‚çŠ¶æ€ï¼ˆå‘ç°å·²ç»éƒ½è¢«Approvedï¼‰
$ kubectl get csr
NAME                                                   AGE     SIGNERNAME                                    REQUESTOR           CONDITION
node-csr-01keemXrwk85QRvmxmKD7BL8Pe8-UpCYmEOdHovJMTE   3m11s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Approved,Issued
node-csr-mhdJODMPp8mQwJrnW-Gl2baQlWWgcrOvrYt3jmbw-dM   3m11s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Approved,Issued
node-csr-rgY6WzL2gwGFa5XyWLgJ4_ypJUPtbruuLloygUQ80P8   4m34s   kubernetes.io/kube-apiserver-client-kubelet   kubelet-bootstrap   Approved,Issued

# å½“nodeèŠ‚ç‚¹æˆåŠŸè¢«å…è®¸åï¼Œæˆ‘ä»¬ä¹‹å‰è®¾ç½®çš„ä¸€äº›é…ç½®å°±ä¼šè‡ªåŠ¨å‘kubelet è¿›è¡Œé¢å‘è¯ä¹¦ã€‚
# å½“æ²¡æœ‰æ¥å—nodeçš„csrè¯·æ±‚æ—¶ï¼Œå®¢æˆ·ç«¯çš„è¯ä¹¦å±äºé¢å‘ä¸­ï¼Œå½“æ¥å—åï¼Œè¯¥è¯ä¹¦æ­£å¼ç”Ÿæˆï¼Œä»æ­¤kubeletå°±å¯ä»¥æ„‰å¿«çš„ç©è€äº†

$ ls -lt /data/kubernetes/ssl/* | head -5
lrwxrwxrwx 1 root root   59 Sep 13 16:10 /data/kubernetes/ssl/kubelet-client-current.pem -> /data/kubernetes/ssl/kubelet-client-2020-09-13-16-10-05.pem
-rw------- 1 root root 1228 Sep 13 16:10 /data/kubernetes/ssl/kubelet-client-2020-09-13-16-10-05.pem
-rw-r--r-- 1 root root 2274 Sep 13 16:05 /data/kubernetes/ssl/kubelet.crt
-rw------- 1 root root 1675 Sep 13 16:05 /data/kubernetes/ssl/kubelet.key

# æ­¤æ—¶æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹é›†ç¾¤çš„èŠ‚ç‚¹çŠ¶æ€ä¿¡æ¯

$ kubectl get nodes
NAME            STATUS   ROLES    AGE     VERSION
192.168.0.145   Ready    <none>   4m33s   v1.19.0
192.168.0.23    Ready    <none>   4m17s   v1.19.0
192.168.0.230   Ready    <none>   4m11s   v1.19.0

```

è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬çš„nodeèŠ‚ç‚¹ç°åœ¨çœ‹èµ·æ¥ä¹Ÿå·²ç»å°±ç»ªäº†ã€‚ä¸è¿‡çœŸçš„å®Œå…¨å°±ç»ªäº†å—ï¼Ÿè¿˜è®°å¾—å‰é¢è¯´åˆ°NodeèŠ‚ç‚¹çœŸæ­£å¯è¿è¡Œï¼Œé™¤äº†Runtimeçš„Dockerä¹‹å¤–ï¼Œè¿˜æ˜¯éœ€è¦CNI æ¥å°†é›†ç¾¤çš„Podæ‰“é€šçš„ã€‚

#### 4.éƒ¨ç½²CNIæ’ä»¶

`æ³¨æ„:` ç”±äºæ–°ç‰ˆæœ¬çš„etcdé»˜è®¤æ˜¯V3æ¥å£çš„ï¼Œå¹¶ä¸”Flannelé»˜è®¤ä¸æ”¯æŒV2æ¥å£ï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨Clicoè¿›è¡Œå®‰è£…ã€‚

`æ³¨æ„:` ç”±äºæˆ‘ä»¬æ˜¯ä½¿ç”¨é¢å¤–çš„CNIæ’ä»¶ï¼Œå› æ­¤åœ¨Kubeletçš„é…ç½®ä¸­éœ€è¦æ˜ç¡®æŒ‡å®šå¦‚ä¸‹é…ç½®: 

```
--network-plugin=cni --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin

# åœ¨æŒ‡å®šäº†ä¸Šè¿°é…ç½®åï¼Œé‡å¯kubeleç»„ä»¶ä¼šé‡å¯æˆåŠŸï¼Œä½†æ˜¯ä¼šå‘ç°kubectl get nodes æ—¶èŠ‚ç‚¹å¤„äºæœªå°±ç»ªçŠ¶æ€ï¼Œæ­¤æ—¶éœ€è¦å®‰è£…CNIæ’ä»¶åå³å¯
```

[Clico](https://docs.projectcalico.org/getting-started/kubernetes/quickstart)

[ä»å¤´å¼€å§‹å®‰è£…Calicoç½‘ç»œ](https://docs.projectcalico.org/getting-started/kubernetes/hardway/)


```
$ mkdir -p /etc/cni/net.d /opt/cni/bin

$ kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml


$ kubectl create -f https://docs.projectcalico.org/manifests/custom-resources.yaml
 
$ watch kubectl get pods -n calico-system

$ kubectl get pods -n tigera-operator
NAME                              READY   STATUS    RESTARTS   AGE
tigera-operator-b96747c7d-mmv9z   1/1     Running   0          6m41s

$ kubectl get pods -n calico-system
NAME                                       READY   STATUS              RESTARTS   AGE
calico-kube-controllers-69fbbf7967-sv9jk   1/1     Running             0          5m35s
calico-node-cgrdz                          0/1     Init:0/2            0          5m35s
calico-node-cr7v8                          1/1     Running             0          5m35s
calico-node-vnw7t                          0/1     Init:0/2            0          5m35s
calico-typha-559c75f66d-j59mm              1/1     Running             0          3m37s
calico-typha-559c75f66d-nlgqg              0/1     ContainerCreating   0          5m36s
calico-typha-559c75f66d-rckgk              0/1     ContainerCreating   0          3m37s


# å¯ä»¥çœ‹åˆ°ï¼Œå½“ä¸€ä¸ªcalico-nodeèŠ‚ç‚¹å®‰è£…æˆåŠŸåï¼Œå¯¹åº”çš„nodeèŠ‚ç‚¹çŠ¶æ€å°±ä¼šå˜ä¸ºå°±ç»ªçŠ¶æ€
$ kubectl get nodes
NAME            STATUS     ROLES    AGE   VERSION
192.168.0.145   NotReady   <none>   21h   v1.19.0
192.168.0.23    NotReady   <none>   21h   v1.19.0
192.168.0.230   Ready      <none>   21h   v1.19.0


$ kubectl get pods -n calico-system
NAME                                       READY   STATUS    RESTARTS   AGE
calico-kube-controllers-69fbbf7967-sv9jk   1/1     Running   0          13h
calico-node-cgrdz                          1/1     Running   0          13h
calico-node-cr7v8                          1/1     Running   0          13h
calico-node-vnw7t                          1/1     Running   0          13h
calico-typha-559c75f66d-j59mm              1/1     Running   0          13h
calico-typha-559c75f66d-nlgqg              1/1     Running   0          13h
calico-typha-559c75f66d-rckgk              1/1     Running   0          13h

$ kubectl get nodes
NAME            STATUS   ROLES    AGE   VERSION
192.168.0.145   Ready    <none>   35h   v1.19.0
192.168.0.23    Ready    <none>   35h   v1.19.0
192.168.0.230   Ready    <none>   35h   v1.19.0

# å½“èŠ‚ç‚¹éƒ½å°±ç»ªåï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¼šæœ‰å…·ä½“çš„CNIæ’ä»¶ï¼ŒCNIçš„é…ç½®ä¿¡æ¯ä»¥åŠCNIçš„podçš„kubeconfig

$ ls /opt/cni/bin/
bandwidth  calico  calico-ipam  flannel  host-local  install  loopback  portmap  tuning

$ ls /etc/cni/net.d/
10-calico.conflist  calico-kubeconfig

# å…¶å®è¿™é‡Œèƒ½å¤Ÿçœ‹å‡ºæ¥ï¼Œæˆ‘ä»¬çš„calicoçš„CNIæ’ä»¶ï¼Œé»˜è®¤æ˜¯ä½¿ç”¨çš„kubernetesçš„datastoreæ–¹å¼
$ cat /etc/cni/net.d/10-calico.conflist
{
  "name": "k8s-pod-network",
  "cniVersion": "0.3.1",
  "plugins": [
    {
      "type": "calico",
      "datastore_type": "kubernetes",
      "mtu": 1410,
      "nodename_file_optional": false,
      "log_file_path": "/var/log/calico/cni/cni.log",
      "ipam": {
          "type": "calico-ipam",
          "assign_ipv4" : "true",
          "assign_ipv6" : "false"
      },
      "container_settings": {
          "allow_ip_forwarding": false
      },
      "policy": {
          "type": "k8s"
      },
      "kubernetes": {
          "kubeconfig": "/etc/cni/net.d/calico-kubeconfig"
      }
    },
    {"type": "portmap", "snat": true, "capabilities": {"portMappings": true}}
  ]

```

#### 5.é…ç½®Calicoç½‘ç»œ

[calicoctl](https://docs.projectcalico.org/getting-started/clis/calicoctl/install)

```
# ä¸‹è½½calicoctl 
$ curl -O -L  https://github.com/projectcalico/calicoctl/releases/download/v3.16.1/calicoctl

$ chmod a+x calicoctl && mv calicoctl /usr/sbin/

```

[é…ç½®calicoctlè¿æ¥åˆ°æ•°æ®å­˜å‚¨å±‚](https://docs.projectcalico.org/getting-started/clis/calicoctl/configure/)

Calicoctl å¯ä»¥é…ç½®ä»etcdé›†ç¾¤æˆ–è€…Kubernetesé›†ç¾¤çš„APIä¸­å»è¿›è¡Œè¯»å†™ç›¸å…³çš„æ•°æ®ã€‚

- [etcd datastore](https://docs.projectcalico.org/getting-started/clis/calicoctl/configure/etcd)
- [kubernetes API datastore](https://docs.projectcalico.org/getting-started/clis/calicoctl/configure/kdd)

æ³¨æ„: `calicoctl`ç¨‹åºé»˜è®¤ä»é…ç½®æ–‡ä»¶`/etc/calico/calicoctl.cfg`ä¸­è¿›è¡Œè¯»å–ç›¸å…³çš„é…ç½®æ–‡ä»¶ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨`--config`å‚æ•°æŒ‡å®šé…ç½®æ–‡ä»¶ã€‚åŒæ—¶ï¼Œå¦‚æœç¨‹åºæ— æ³•ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–ï¼Œå°†ä¼šä»é»˜è®¤çš„ç¯å¢ƒå˜é‡ä¸­è¿›è¡Œç›¸å…³é…ç½®çš„ä½¿ç”¨ã€‚

```
# calicoct.cfg é…ç½®æ–‡ä»¶å®ä¾‹
apiVersion: projectcalico.org/v3
kind: CalicoAPIConfig
metadata:
spec:
  datastoreType: "etcdv3"
  etcdEndpoints: "http://etcd1:2379,http://etcd2:2379"
  ...

```

**é…ç½®ETCDçš„æ•°æ®å­˜å‚¨**

```
# å°†etcdç›¸å…³çš„è¯ä¹¦å‡†å¤‡åˆ°å›ºå®šçš„ä½ç½®

$ cat  /etc/calico/calicoctl.cfg
apiVersion: projectcalico.org/v3
kind: CalicoAPIConfig
metadata:
spec:
  etcdEndpoints: https://192.168.0.230:2379,https://192.168.0.23:2379,https://192.168.0.145:2379
  etcdKeyFile: /data/etcd/ssl/etcd-key.pem
  etcdCertFile: /data/etcd/ssl/etcd.pem
  etcdCACertFile: /data/etcd/ssl/ca.pem


# è·å–calicoctl çš„calicoèŠ‚ç‚¹
$ calicoctl get nodes
NAME

```

**é…ç½®Kubernetes APIçš„æ•°æ®å­˜å‚¨**

```
$  export KUBECONFIG=/data/kubernetes/cfg/kubelet.kubeconfig
$  export DATASTORE_TYPE=kubernetes

$ calicoctl get nodes -o wide
NAME            ASN         IPV4               IPV6
192.168.0.145   (unknown)   192.168.0.145/24
192.168.0.23    (unknown)   192.168.0.23/24
192.168.0.230   (unknown)   192.168.0.230/24

# ä¹Ÿå¯ä»¥é…ç½®åˆ°é…ç½®æ–‡ä»¶ä¸­
$ cat /etc/calico/calicoctl.cfg
apiVersion: projectcalico.org/v3
kind: CalicoAPIConfig
metadata:
spec:
  datastoreType: "kubernetes"
  kubeconfig: "/data/kubernetes/cfg/kubelet.kubeconfig"


```

ä¹Ÿå¯ä»¥å°†`calicoctl` ç›´æ¥ä»¥podçš„æ–¹å¼éƒ¨ç½²: 

```
# etcdä¸ºåç«¯å­˜å‚¨çš„pod
$ kubectl apply -f https://docs.projectcalico.org/manifests/calicoctl-etcd.yaml

# kubernetes api ä¸ºåç«¯å­˜å‚¨çš„Pod
$  kubectl apply -f https://docs.projectcalico.org/manifests/calicoctl.yaml


# ä½¿ç”¨calicoctl æŸ¥çœ‹é›†ç¾¤ç›¸å…³ä¿¡æ¯
$ kubectl exec -ti -n kube-system calicoctl -- /calicoctl get profiles -o wide

$ alias calicoctl="kubectl exec -i -n kube-system calicoctl -- /calicoctl"

# ç„¶åå°±å¯ä»¥åœ¨èŠ‚ç‚¹ä¸Šå¼€å¿ƒçš„æ‰§è¡Œcalicoctl å‘½ä»¤äº†

$ calicoctl node status
Calico process is running.

IPv4 BGP status
+---------------+-------------------+-------+----------+-------------+
| PEER ADDRESS  |     PEER TYPE     | STATE |  SINCE   |    INFO     |
+---------------+-------------------+-------+----------+-------------+
| 192.168.0.145 | node-to-node mesh | up    | 03:06:11 | Established |
| 192.168.0.23  | node-to-node mesh | up    | 03:06:45 | Established |
+---------------+-------------------+-------+----------+-------------+

```
